{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we'll be using the Keras library\n",
    "# http://keras.io\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create training set\n",
    "numFeatures = 3\n",
    "X = np.random.randint(0,2,size=(100,numFeatures))\n",
    "Y = np.where(np.sum(X,1)>=2,1,0)\n",
    "Y.shape=(np.size(X,0),1)\n",
    "\n",
    "# create test set\n",
    "Xt = np.random.randint(0,2,size=(100,numFeatures))\n",
    "yt = np.where(np.sum(Xt,1)>=2,1,0)\n",
    "yt.shape=(np.size(Xt,0),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X[:10][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.shape(X)\n",
    "print\n",
    "print np.shape(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the network layers\n",
    "\n",
    "inputLayerSize = np.shape(X)[1] # equals the number of features\n",
    "hiddenLayerSize = 8 # number of nodes in each hidden layer (could also make each hidden layer a different size)\n",
    "\n",
    "model = Sequential() # our model will be a linear stack of layers, one after the other\n",
    "\n",
    "# add the layers to the network\n",
    "model.add(Dense(hiddenLayerSize, input_dim=inputLayerSize, init='uniform', activation='relu')) # input layer\n",
    "model.add(Dense(hiddenLayerSize, init='uniform', activation='relu')) # hidden layer\n",
    "#model.add(Dense(hiddenLayerSize, init='uniform', activation='relu')) # hidden layer\n",
    "#model.add(Dense(hiddenLayerSize, init='uniform', activation='relu')) # hidden layer\n",
    "#model.add(Dense(hiddenLayerSize, init='uniform', activation='relu')) # hidden layer\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid')) # output layer (sigmoid initialization)\n",
    "\n",
    "# Compile model\n",
    "# loss = Loss/Cost Function type \n",
    "# optimizer =~ gradient descent algorithm\n",
    "# metrics = metric by which to monitor performance\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "# nb_epoch = number of iterations\n",
    "# batch_size = number of training examples \"passed\" before the weights are updated\n",
    "# here the weights are updated after 10 training examples are \"passed\" (i.e. 10 times per iteration)\n",
    "model.fit(X, Y, nb_epoch=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# evaluate the model on the training set\n",
    "print\n",
    "scores = model.evaluate(X, Y)\n",
    "print\n",
    "print\n",
    "print 'Training Set Accuracy: ', scores[1]*100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# evaluate the model on the test set\n",
    "print\n",
    "scores = model.evaluate(Xt, yt)\n",
    "print\n",
    "print\n",
    "print 'Test Set Accuracy: ', scores[1]*100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check to make sure that it's better than just a random guess\n",
    "print\n",
    "print 'Random Accuracy of Training Set: ', np.max([np.sum(Y)*1./np.shape(Y)[0], 1. - np.sum(Y)*1./np.shape(Y)[0]])\n",
    "print\n",
    "print 'Random Accuracy of Test Set: ', np.max([np.sum(yt)*1./np.shape(yt)[0], 1. - np.sum(yt)*1./np.shape(yt)[0]])\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ws = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in ws:\n",
    "    print np.shape(i),'\\n'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
