{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% reset -f\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "# np.set_printoptions(threshold='nan')\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for j in range(10):\n",
    "    fileNames = glob.glob('trainingDigits/' + str(j) + '_*.txt')\n",
    "    for fN in fileNames:\n",
    "        with open(fN, 'r') as f:\n",
    "            rd = f.read()\n",
    "            if '\\r\\n' in rd:\n",
    "                rd = rd.replace('\\r\\n','')\n",
    "            elif '\\n' in rd:\n",
    "                rd = rd.replace('\\n','')\n",
    "            X.append([int(i) for i in rd])\n",
    "            y.append(j)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "idx = range(X.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "X = X[idx,:]\n",
    "y = y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xt = []\n",
    "yt = []\n",
    "\n",
    "for j in range(10):\n",
    "    fileNames = glob.glob('testDigits/' + str(j) + '_*.txt')\n",
    "    for fN in fileNames:\n",
    "        with open(fN, 'r') as f:\n",
    "            rd = f.read()\n",
    "            if '\\r\\n' in rd:\n",
    "                rd = rd.replace('\\r\\n','')\n",
    "            elif '\\n' in rd:\n",
    "                rd = rd.replace('\\n','')\n",
    "            Xt.append([int(i) for i in rd])\n",
    "            yt.append(j)\n",
    "\n",
    "Xt = np.array(Xt)\n",
    "yt = np.array(yt)\n",
    "\n",
    "idx = range(Xt.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "Xt = Xt[idx,:]\n",
    "yt = yt[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRID SEARCH\n",
    "\n",
    "\n",
    "# # Create hidden layer size space\n",
    "# hList = range(5,51,5)\n",
    "\n",
    "# # Create alpha space (i.e. L2 regularization penalty parameter space)\n",
    "# aList = []\n",
    "# for k in [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]:\n",
    "#     for j in [1,1.25,2.5,3.75,5,6.25,7.5,8.75]:\n",
    "#         aList.append(j*k)\n",
    "\n",
    "# # instantiate an MLP model to run the search on\n",
    "# mlpModel = MLPClassifier(max_iter=200)\n",
    "\n",
    "# # Create hyperparameter options\n",
    "# hyperparameters = dict(hidden_layer_sizes=hList, alpha=aList)\n",
    "\n",
    "# # run a grid search for hyperparameter tuning\n",
    "# searchModel = GridSearchCV(mlpModel, hyperparameters, cv=3, verbose=1)\n",
    "# best_model = searchModel.fit(X, y)\n",
    "\n",
    "# # just out of curiosity, what was the result of the hyperparameter tuning\n",
    "# bestHid = best_model.best_estimator_.get_params()['hidden_layer_sizes']\n",
    "# bestReg = best_model.best_estimator_.get_params()['alpha']\n",
    "# print 'Best hidden layer size:', bestHid\n",
    "# print 'Best regularization parameter:', bestReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 30.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hidden layer size: (155, 165, 185)\n",
      "Best regularization parameter: 0.0039000000000000003\n"
     ]
    }
   ],
   "source": [
    "### RANDOM SEARCH\n",
    "\n",
    "\n",
    "# Create hidden layer size space\n",
    "hSpace = range(5,201,5)\n",
    "hList = []\n",
    "for h1 in hSpace:\n",
    "    for h2 in hSpace:\n",
    "        for h3 in hSpace:\n",
    "            hList.append((h1,h2,h3))\n",
    "\n",
    "\n",
    "# Create alpha space (i.e. L2 regularization penalty parameter space)\n",
    "aList = []\n",
    "for k in [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]:\n",
    "    for j in np.linspace(1,10,91):\n",
    "        aList.append(j*k)\n",
    "\n",
    "# instantiate an MLP model to run the search on\n",
    "mlpModel = MLPClassifier(max_iter=200)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(hidden_layer_sizes=hList, alpha=aList)\n",
    "\n",
    "rnd = np.random.randint(100)\n",
    "searchModel = RandomizedSearchCV(mlpModel, hyperparameters, random_state=rnd, n_iter=60, cv=3, verbose=1, n_jobs=-1)\n",
    "best_model = searchModel.fit(X, y)\n",
    "\n",
    "# just out of curiosity, what was the result of the hyperparameter tuning\n",
    "bestHid = best_model.best_estimator_.get_params()['hidden_layer_sizes']\n",
    "bestReg = best_model.best_estimator_.get_params()['alpha']\n",
    "print 'Best hidden layer size:', bestHid\n",
    "print 'Best regularization parameter:', bestReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.88583509513742"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction using the model from the search\n",
    "\n",
    "# yp = best_model.predict(Xt)\n",
    "yp = best_model.best_estimator_.predict(Xt)\n",
    "\n",
    "100.0*sum(yp == yt)/yt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.67441860465117"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction using a new model initialized with results from the search (for comparison)\n",
    "\n",
    "new_mlpModel = MLPClassifier(hidden_layer_sizes=bestHid, alpha=bestReg, max_iter=200)\n",
    "new_mlpModel.fit(X,y);\n",
    "\n",
    "yp = new_mlpModel.predict(Xt)\n",
    "\n",
    "100.0*sum(yp == yt)/yt.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
